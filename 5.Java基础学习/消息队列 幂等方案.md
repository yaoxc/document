# 一 、 全局唯一 ID + 去重存储（最通用）

## 1、原理

1. 生产端**每条消息携带业务唯一键**（订单号、UUID、消息ID 等）。
2. 消费端**先查后处理**，用**Redis SetNX**、**数据库唯一索引**或**布隆过滤器**记录“已消费”：
   - `SETNX order_123 1` 返回 1 → 继续处理；返回 0 → 直接丢弃 

**优点**：实现简单，不依赖 MQ 品牌。
**缺点**：需额外存储，高并发时要考虑 **TTL + 分片** 防止 Redis 打爆。

> “用 Redis 做幂等去重时，**每来一条消息就要写一次唯一键**。高并发下如果只管写不管清理，内存会被无限累积，最终打爆。”
>
> 因此需要 **两个动作**：
>
> 1. **给每条记录加“生命周期”**（TTL）
> 2. **把大 Key 拆成多个小 Key**（分片 / 分桶）

---

## 2、实现

### 1、依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

### 2、 全局唯一 ID + Redis SETNX（高并发）

```java
@Component
@RabbitListener(queues = "order.queue")
public class OrderConsumer {

    @Autowired private StringRedisTemplate redis;

    @RabbitHandler // 处理队列中OrderMessage类型的消息
    public void handle(OrderMessage msg) {
      // 1. 生成全局唯一幂等Key：前缀+订单ID（订单ID是天然的唯一标识）
			String key = "order:idempotent:" + msg.getOrderId();

			/*
         2. 执行Redis SETNX（Set If Not Exists）原子操作：
            - 逻辑：只有当key不存在时，才会设置值为"1"，并指定10分钟过期时间
            - 原子性：Redis单线程执行，避免多线程/多实例并发时重复设置
            - 返回值：true=key不存在，首次消费；false=key已存在，重复消费
         */
			Boolean first = redis.opsForValue().setIfAbsent(key, "1", Duration.ofMinutes(10));

			// 3. 若key已存在（first=false），判定为重复消息，直接返回
			if (Boolean.FALSE.equals(first)) {        
    		log.warn("重复消息丢弃 {}", msg.getOrderId());
    		return;
			}

			// 4. 首次消费：执行真正的业务逻辑（仅执行一次）
			doSaveOrder(msg);
    }
}
```

- `setIfAbsent` 仅完成「不存在则设置 + 过期时间」，**没有删除动作**；
- 业务处理完成后，key 会一直存在，直到 10 分钟后 Redis 自动清理；
- 即使 `doSaveOrder` 执行失败 / 抛出异常，key 也不会被移除。

#### 1. 潜在问题（为什么需要考虑移除？）

如果业务执行失败（比如 `doSaveOrder` 抛异常），但 key 已经存在：

- 10 分钟内该订单的重试消息会被判定为「重复消息」直接丢弃，导致业务永久失败；
- 若业务需要重试，这种 “仅靠过期时间” 的方式会限制重试窗口（只能等 10 分钟后 key 过期）。

#### 2、优化方案

实际业务中，需根据「**业务是否允许重试**」设计 Key 移除逻辑，以下是 3 种主流方案：

##### 方案 1：业务成功后主动删除（推荐，适配重试场景）

**核心逻辑**：

- 业务执行成功 → 立即删 Key（释放内存 + 允许异常重试）；

- 业务执行失败 → 保留 Key（不允许重试，避免重复消费）
  - “不允许重试 + 保留 Key” 的逻辑下，异常消息确实会面临「无法自动处理」的问题 —— 但这并非设计漏洞，而是**业务场景取舍后的结果**。

```java
@RabbitHandler
public void handle(OrderMessage msg) {
    String key = "order:idempotent:" + msg.getOrderId();
    Boolean first = redis.opsForValue().setIfAbsent(key, "1", Duration.ofMinutes(10));
    if (Boolean.FALSE.equals(first)) {        
        log.warn("重复消息丢弃 {}", msg.getOrderId());
        return;
    }

    try {
        // 执行核心业务
        doSaveOrder(msg);
        // 业务成功：主动删除Key（关键！）
        redis.delete(key); 
    } catch (Exception e) {
        log.error("订单处理失败，订单ID：{}", msg.getOrderId(), e);
        // 业务失败：不删Key → 拦截后续重复消息，避免多次失败
        // 若需要重试，可在此处删除Key（让下一次消息能重新执行）
        // redis.delete(key);
        throw e; // 抛出异常，触发RabbitMQ重试（需配合MQ重试策略）
    }
}
```

##### 方案 2：使用 Redis 分布式锁 + finally 删除（适配长耗时业务）

如果 `doSaveOrder` 执行耗时较长（超过 10 分钟），过期时间可能不够，可改用「分布式锁 + finally 删除」：

```java
@RabbitHandler
public void handle(OrderMessage msg) {
    String key = "order:idempotent:" + msg.getOrderId();
    // 加锁：无过期时间（避免业务没执行完锁过期）
    Boolean locked = redis.opsForValue().setIfAbsent(key, "1");
    if (Boolean.FALSE.equals(locked)) {        
        log.warn("重复消息丢弃 {}", msg.getOrderId());
        return;
    }

    try {
        // 执行业务（即使耗时超过10分钟也不会被过期）
        doSaveOrder(msg);
    } catch (Exception e) {
        log.error("订单处理失败", e);
        throw e;
    } finally {
        // 无论成功/失败，最终都删除Key（适合「失败后允许立即重试」的场景）
        redis.delete(key); 
    }
}
```

##### 方案 3：基于 Redis Hash 结构 + 状态标记（进阶，适配复杂场景）

如果需要区分「处理中 / 处理成功 / 处理失败」状态，可改用 Hash 结构存储，避免直接删 Key：

```java
@RabbitHandler
public void handle(OrderMessage msg) {
    String key = "order:idempotent:" + msg.getOrderId();
    // 1. 初始化Hash：仅当Key不存在时设置，状态为"PROCESSING"（处理中）
    Boolean init = redis.opsForHash().putIfAbsent(key, "status", "PROCESSING");
    if (Boolean.FALSE.equals(init)) {
        // 2. 检查已有状态：成功则丢弃，失败则重试
        String status = (String) redis.opsForHash().get(key, "status");
        if ("SUCCESS".equals(status)) {
            log.warn("重复消息丢弃 {}", msg.getOrderId());
            return;
        }
    }

    try {
        doSaveOrder(msg);
        // 3. 业务成功：标记为SUCCESS，10分钟后过期
        redis.opsForHash().put(key, "status", "SUCCESS");
        redis.expire(key, Duration.ofMinutes(10));
    } catch (Exception e) {
        // 4. 业务失败：标记为FAIL，保留Key便于排查
        redis.opsForHash().put(key, "status", "FAIL");
        throw e;
    }
}
```

#### 3、异常消息处理

##### 1、先明确：“不允许重试” 的核心前提

异常消息 “不允许重试” 并不是 “放弃处理”，而是指：

- 拒绝「MQ 自动重试」（比如 RabbitMQ 的重试机制会反复推送失败消息，可能导致雪崩）；
- 拒绝「短时间内重复消费」（比如 10 分钟内重复推送的同一条消息直接丢弃）；
- 但异常消息仍需**人工介入 / 异步补偿**处理，而非完全不管。

##### 2、实际业务中解决该问题的 3 套完整方案

###### 方案 1：失败后标记状态 + 死信队列（推荐，自动化处理）

核心思路：**异常消息不直接丢弃，而是转发到「死信队列（DLQ）」**，同时在 Redis 中标记 “失败状态”，死信队列消费端专门处理异常消息（人工介入 / 补偿逻辑）。

步骤 1：配置 RabbitMQ 死信队列（避免原队列阻塞）

```java
// 1. 配置原队列 + 死信交换机/队列
@Configuration
public class RabbitConfig {
    // 死信交换机
    @Bean
    public DirectExchange orderDlxExchange() {
        return new DirectExchange("order.dlx.exchange");
    }
    // 死信队列
    @Bean
    public Queue orderDlxQueue() {
        return QueueBuilder.durable("order.dlx.queue").build();
    }
    // 绑定死信队列到死信交换机
    @Bean
    public Binding orderDlxBinding() {
        return BindingBuilder.bind(orderDlxQueue()).to(orderDlxExchange()).with("order.dlx.key");
    }
    // 原订单队列（指定死信交换机+路由键）
    @Bean
    public Queue orderQueue() {
        return QueueBuilder.durable("order.queue")
                .deadLetterExchange("order.dlx.exchange") // 死信交换机
                .deadLetterRoutingKey("order.dlx.key")    // 死信路由键
                .build();
    }
}
```

步骤 2：改造消费端逻辑（失败后标记状态 + 抛异常触发死信）

```java
@RabbitListener(queues = "order.queue")
public class OrderConsumer {
    @Autowired private StringRedisTemplate redis;
    private static final Logger log = LoggerFactory.getLogger(OrderConsumer.class);

    @RabbitHandler
    public void handle(OrderMessage msg) {
        String key = "order:idempotent:" + msg.getOrderId();
        Boolean first = redis.opsForValue().setIfAbsent(key, "PROCESSING", Duration.ofMinutes(30));
        
        // 重复消息/处理中消息：直接丢弃
        if (Boolean.FALSE.equals(first)) {
            String status = redis.opsForValue().get(key);
            if ("SUCCESS".equals(status)) {
                log.warn("重复消息（已成功）丢弃，订单ID：{}", msg.getOrderId());
                return;
            } else if ("FAIL".equals(status)) {
                log.warn("重复消息（已失败）丢弃，订单ID：{}", msg.getOrderId());
                return;
            }
            log.warn("消息处理中，重复推送丢弃，订单ID：{}", msg.getOrderId());
            return;
        }

        try {
            // 执行业务逻辑
            doSaveOrder(msg);
            // 成功：标记状态+删除Key（或保留状态便于排查）
            redis.opsForValue().set(key, "SUCCESS", Duration.ofHours(24));
            // redis.delete(key); // 也可直接删除
        } catch (Exception e) {
            log.error("订单处理失败，订单ID：{}", msg.getOrderId(), e);
            // 失败：标记状态为FAIL，保留Key（30分钟过期）
            redis.opsForValue().set(key, "FAIL", Duration.ofMinutes(30));
            // 抛出异常 → 触发RabbitMQ将消息转发到死信队列
            throw new AmqpRejectAndDontRequeueException("业务执行失败，转发到死信队列");
        }
    }

    // 死信队列消费端：专门处理失败消息（人工介入/补偿）
    @RabbitListener(queues = "order.dlx.queue")
    public void handleDlx(OrderMessage msg) {
        String key = "order:idempotent:" + msg.getOrderId();
        String status = redis.opsForValue().get(key);
        if ("FAIL".equals(status)) {
            // 1. 记录失败日志到数据库/告警平台
            log.error("死信队列处理失败订单，订单ID：{}，需人工介入", msg.getOrderId());
            // 2. 执行补偿逻辑（比如调用退款接口、通知运营）
            doCompensate(msg);
            // 3. 补偿完成后标记为COMPENSATED
            redis.opsForValue().set(key, "COMPENSATED", Duration.ofHours(24));
        }
    }
}
```

---

- throw new AmqpRejectAndDontRequeueException("业务执行失败，转发到死信队列");   为什么抛出这个异常，会将消息投入死信队列？
  - 核心是**RabbitMQ 的死信队列（DLQ）机制 + Spring AMQP 的异常处理规则** 共同作用的结果。

---

1、先明确核心前提：死信队列的触发条件

RabbitMQ 中，消息进入死信队列的核心条件是**消息被拒绝（reject）且不重新入队**，满足以下场景之一就会触发：

1. 消费者明确拒绝消息（`basicReject`/`basicNack`），且设置 `requeue=false`；
2. 消息在队列中超过设置的「过期时间（TTL）」；
3. 队列达到最大长度，头部消息被挤掉；

而我们代码中 `AmqpRejectAndDontRequeueException` 对应的是**第一种场景**（拒绝消息 + 不重入队）。

---

2、`AmqpRejectAndDontRequeueException` 的底层作用

`AmqpRejectAndDontRequeueException` 是 Spring AMQP 框架提供的**专用异常**，其核心作用是：

> 告诉 Spring AMQP 的消息监听容器（Listener Container）：「这个消息处理失败了，拒绝接收，且不要重新放回原队列」。

具体执行流程如下：

1. 消费者抛出 `AmqpRejectAndDontRequeueException` → Spring AMQP 捕获到该异常；
2. Spring AMQP 调用 RabbitMQ 的客户端 API（`Channel.basicReject(deliveryTag, false)`）：
   - `deliveryTag`：当前消息的唯一标识；
   - `false`：表示「不重新入队（requeue=false）」；
3. RabbitMQ 收到 `basicReject(deliveryTag, false)` 指令后，检查原队列是否配置了「死信交换机（DLX）」；
4. 若原队列绑定了死信交换机 + 路由键 → RabbitMQ 自动将这条被拒绝的消息转发到配置的死信队列；
5. 若原队列未配置死信交换机 → 这条消息会被直接丢弃（这也是为什么必须先配置死信队列）。

---

3、关键配置：原队列必须绑定死信属性

消息能自动进入死信队列的**前提**是：我们在定义原队列（`order.queue`）时，已经通过代码指定了「死信交换机」和「死信路由键」（这是核心配置，缺一不可）。

回顾之前的队列配置代码：

```java
@Bean
public Queue orderQueue() {
    return QueueBuilder.durable("order.queue")
            .deadLetterExchange("order.dlx.exchange") // 绑定死信交换机
            .deadLetterRoutingKey("order.dlx.key")    // 绑定死信路由键
            .build();
}
```

- `deadLetterExchange`：告诉 RabbitMQ「当这条队列的消息成为死信时，转发到这个交换机」；
- `deadLetterRoutingKey`：告诉 RabbitMQ「转发到死信交换机时，使用这个路由键匹配死信队列」；

正是因为有了这两个配置，被 `AmqpRejectAndDontRequeueException` 拒绝的消息，才会被 RabbitMQ 自动路由到 `order.dlx.queue` 死信队列。

---

4、流程图

```tex
┌─────────────┐    消费消息    ┌─────────────┐
│  order.queue │ ────────────→ │ 消费者      │
└─────────────┘                └──────┬──────┘
                                       │
                                       ▼ 抛出 AmqpRejectAndDontRequeueException
┌─────────────┐    basicReject(deliveryTag, false)    ┌─────────────┐
│ Spring AMQP │ ───────────────────────────────────→ │ RabbitMQ    │
└─────────────┘                                       └──────┬──────┘
                                                          │
                                                          ▼ 检查原队列的死信配置
┌─────────────┐    转发消息（按DLX+路由键）    ┌─────────────┐
│ order.dlx.queue │ ←──────────────────────── │ RabbitMQ    │
└─────────────┘                               └─────────────┘
```



---

###### 方案 2：失败后写入异常表 + 定时任务补偿（兜底方案）

如果不想用死信队列，可将失败消息写入「异常订单表」，通过定时任务扫描异常表，人工确认后触发补偿：

```java
@RabbitHandler
public void handle(OrderMessage msg) {
    String key = "order:idempotent:" + msg.getOrderId();
    Boolean first = redis.opsForValue().setIfAbsent(key, "PROCESSING", Duration.ofMinutes(30));
    if (Boolean.FALSE.equals(first)) {
        log.warn("重复消息丢弃，订单ID：{}", msg.getOrderId());
        return;
    }

    try {
        doSaveOrder(msg);
        redis.opsForValue().set(key, "SUCCESS", Duration.ofHours(24));
    } catch (Exception e) {
        log.error("订单处理失败，订单ID：{}", msg.getOrderId(), e);
        // 1. 标记Redis状态为FAIL
        redis.opsForValue().set(key, "FAIL", Duration.ofMinutes(30));
        // 2. 写入异常订单表（含失败原因、订单信息）
        exceptionOrderService.save(new ExceptionOrder(msg.getOrderId(), e.getMessage(), LocalDateTime.now()));
        // 3. 不抛异常，避免MQ重复推送
    }
}

// 定时任务：每小时扫描异常表，通知运营或自动补偿
@Scheduled(cron = "0 0 */1 * * ?")
public void compensateExceptionOrder() {
    List<ExceptionOrder> exceptionOrders = exceptionOrderService.listByStatus("UNHANDLED");
    for (ExceptionOrder order : exceptionOrders) {
        try {
            // 人工确认后执行补偿（或自动尝试一次补偿）
            doCompensate(order.getOrderId());
            exceptionOrderService.updateStatus(order.getId(), "COMPENSATED");
            // 更新Redis状态
            redis.opsForValue().set("order:idempotent:" + order.getOrderId(), "COMPENSATED", Duration.ofHours(24));
        } catch (Exception e) {
            log.error("补偿失败，订单ID：{}", order.getOrderId(), e);
        }
    }
}
```

###### 方案 3：失败后立即删除 Key + 限制重试次数（折中方案）

如果业务允许「有限次数重试」（比如最多 3 次），可在 Redis 中记录重试次数，达到次数后停止重试并走异常流程：

```java
@RabbitHandler
public void handle(OrderMessage msg) {
    String key = "order:idempotent:" + msg.getOrderId();
    // Hash结构存储：状态+重试次数
    Map<String, String> initMap = new HashMap<>();
    initMap.put("status", "PROCESSING");
    initMap.put("retryCount", "0");
    Boolean first = redis.opsForHash().putIfAbsent(key, "status", "PROCESSING");
    
    if (Boolean.FALSE.equals(first)) {
        String status = (String) redis.opsForHash().get(key, "status");
        if ("SUCCESS".equals(status)) {
            log.warn("重复消息丢弃，订单ID：{}", msg.getOrderId());
            return;
        }
        // 获取重试次数
        int retryCount = Integer.parseInt((String) redis.opsForHash().get(key, "retryCount"));
        if (retryCount >= 3) {
            log.warn("重试次数达上限，丢弃消息，订单ID：{}", msg.getOrderId());
            redis.opsForHash().put(key, "status", "FAIL");
            return;
        }
        // 增加重试次数
        redis.opsForHash().increment(key, "retryCount", 1);
    } else {
        // 首次消费：初始化重试次数
        redis.opsForHash().put(key, "retryCount", "0");
        redis.expire(key, Duration.ofMinutes(30));
    }

    try {
        doSaveOrder(msg);
        redis.opsForHash().put(key, "status", "SUCCESS");
    } catch (Exception e) {
        log.error("订单处理失败，订单ID：{}", msg.getOrderId(), e);
        // 失败后删除Key → 允许MQ重试（最多3次）
        redis.delete(key);
        throw e;
    }
}
```

##### 3、核心原则总结

1. “不允许重试” ≠ “放弃处理”：
   - 拒绝的是「无限制自动重试」（避免雪崩）；
   - 必须通过死信队列 / 异常表 / 定时任务做「兜底处理」；
2. Redis Key 的管理逻辑：
   - 成功：标记 SUCCESS（或删除）；
   - 失败：标记 FAIL + 走异常流程，而非直接删除；
3. 异常消息的处理优先级：
   - 死信队列（自动化）> 异常表 + 定时任务（半自动化）> 人工排查（兜底）。

通过以上方案，既保证了「不允许短时间重复重试」的幂等性要求，又解决了「异常消息无法处理」的问题，是实际业务中最常用的落地方式。



### 4、Redis 大 Key问题 

- String key = "order:idempotent:" + msg.getOrderId();  为什么会造成大Key，在Redis中是怎么存的？

把 `key` 写成  
```
order:idempotent:2400000001
order:idempotent:2400000002
...
```
**本身并不会产生「大 Key」**；这里说的“大 Key”不是 **key 字符串很长**，而是 **同一个 Redis 键** 里 **聚集了大量 field / member** 导致 **value 巨大**。

-------------------------
1. 场景还原——什么时候会变大
-------------------------
如果你为了“省内存”而把所有去重 ID 塞进 **一个 hash 或 set**：
```java
// 错误示范：全局只有一个键
redis.hset("order:idempotent", orderId, "1");   // 同一个 hash 键
```
或者
```java
redis.sadd("order:idempotent", orderId);       // 同一个 set 键
```
**order:idempotent** 就是 **唯一的大 Key**，里面不断累积 `orderId` → 元素个数从 100 → 1000 万 → 亿级：
- 内存占用线性上涨；
- 删除/过期时 **DEL** 会阻塞秒级（Redis 单线程）；
- 查询、扩缩容、rehash 也会卡顿；
- 集群模式下 **整份数据落在同一槽、同一节点**，无法水平扩展。

-------------------------
2. Redis 底层怎么存
-------------------------
- **string** 类型：一个 key → 一个 SDS 对象，长度再大都算 **单个键值对**，不会成为“大 Key”；
- **hash / set / zset / list**：一个 key → 一个 **dict/ziplist/listpack** 结构，**元素越多 value 越大**，才会形成“大 Key”；
- 元素过千万时，一次 **DEL** 需要释放整块 dict + 所有 SDS，**阻塞整条线程**。

-------------------------
3. 正确做法——打散
-------------------------
把 **“一个大集合”** 拆成 **“N 个小集合”**（分片 / 分桶）：
```java
// 每条消息只生成 **string** 键，元素级过期
String key = "idemp:" + (orderId.hashCode() & 63) + ":" + orderId;
redis.setex(key, 86400, "1");
```
- 每个 key 的元素数量 = 1，**不会形成大 Key**；
- 过期由 **TTL** 自动完成，无需整体删除；
- 64 个分片均匀落在 **Redis Cluster** 不同槽，**水平扩展**无热点。

-------------------------
一句话
> **“大 Key” 指 value 巨大（元素多），不是 key 字符串长**；  
> 去重场景千万别把所有 ID 塞进 **同一个 hash/set**，应该 **一条消息一个独立 key** 或 **分片 hash + 滚动桶**，才能避免 Redis 阻塞、打爆内存。



#### key分片、分桶计算

- 大Key分片分桶，对于同一个id，算出的小key是唯一的么？

是**唯一的**——只要分片算法是**确定性**的（同一个输入永远得到同一个输出），就不会出现“同一个 orderId 算到不同小 key”的情况，也就不会漏判或误判重复。

最简单的确定性算法：

```java
int shard = (orderId.hashCode() & Integer.MAX_VALUE) % SHARD_COUNT;
```

- `orderId.hashCode()` 固定  
- `& Integer.MAX_VALUE` 抹掉符号位 → 非负  
- `% SHARD_COUNT` 取模 → 0 … SHARD_COUNT-1  

因此同一个 `orderId` 永远落到 **同一个分片号**，再拼接成最终的 **分片键**：

```java
String smallKey = "idemp:" + shard + ":" + orderId;
```

**结论**：  
只要 **SHARD_COUNT 不变**、**hashCode 不变**（String 已满足），**同一个 ID 算出的分片键就是唯一的**，幂等判断不会出错。  
扩容时如果想改 SHARD_COUNT，需要做一次“reshard”迁移或者保持旧值继续用即可。

# 二 、数据库层幂等（业务自带）

- **INSERT … ON DUPLICATE KEY UPDATE**
  或 **主键/唯一索引冲突**时直接返回成功，不再插入 
- **状态机约束**：订单状态只能单向流转，重复消息无法再次更新 

```java
@Entity
@Table(name = "t_order",
       uniqueConstraints = @UniqueConstraint(name = "uk_order_id", columnNames = "orderId"))
public class Order {
    @Id @GeneratedValue
    private Long id;
    private Long orderId;
    private String customer;
}

@Service
@Transactional
public class OrderService {
    @Autowired private OrderRepository repo;

    public void createOrder(Long orderId, String customer) {
        try {
            repo.save(new Order(null, orderId, customer));
        } catch (DataIntegrityViolationException e) {
            log.warn("主键冲突，重复消息丢弃 {}", orderId);
        }
    }
}
```



# 三. MQ 内置幂等（仅 Kafka）

开启 `enable.idempotence=true`，Kafka 会为**每个生产者实例**维护 `<PID, 分区, 序列号>`，Broker 端自动过滤重复序列号，**生产侧不重**

> 注意：只能解决“生产者重试”导致的重复，**消费侧重复仍需业务自己处理**。

```yaml
spring:
  kafka:
    producer:
      bootstrap-servers: localhost:9092
      retries: 3
      enable-idempotence: true          # 关键
      acks: all
      transaction-id-prefix: tx-
```

```java
@Autowired private KafkaTemplate<String, String> template;

public void sendOrder(String orderId){
    template.send("order-topic", orderId, orderId);  // 重复自动过滤
}
```



# 四. 事务消息 + 本地去重表（分布式场景）

1. 发送 **Half Message** 并执行本地事务；
2. 本地事务里**把消息ID写入去重表**（与业务表同库同事务）；
3. 事务提交后再 **Commit** 消息；回滚则 **Rollback** 。
   即使后续重试，去重表已存在同一消息ID，保证幂等。

```java
@Slf4j
@Service
public class TxOrderService {

    @Autowired private RocketMQTemplate rocket;
    @Autowired private JdbcTemplate jdbc;

    @Transactional
    public void createOrder(Long orderId){
        // 1. 业务入库
        jdbc.update("insert into t_order(order_id) values(?)", orderId);

        // 2. 同时写入去重表（与业务同事务）
        jdbc.update("insert into t_msg_log(msg_id) values(?)", orderId);

        // 3. 发送事务消息（half 消息）
        rocket.sendMessageInTransaction("tx-order-topic",
                MessageBuilder.withPayload(orderId).build(), null);
    }

    @RocketMQTransactionListener
    class TxListener implements RocketMQLocalTransactionListener {

        @Override
        public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) {
            return RocketMQLocalTransactionState.COMMIT;  // 本地事务已OK
        }

        @Override
        public RocketMQLocalTransactionState checkLocalTransaction(Message msg) {
            Long orderId = Long.valueOf(new String((byte[]) msg.getPayload()));
            Integer cnt = jdbc.queryForObject(
                    "select count(*) from t_msg_log where msg_id=?", Integer.class, orderId);
            return cnt > 0 ? COMMIT : ROLLBACK;   // 重复检
        }
    }
}
```



# 五. 死信队列 + 重试上限(RabbitMQ)

给消费逻辑设置 **最大重试次数**，超过后转入 **DLQ（死信队列）**，避免无限循环

```java
@Configuration
public class DlxConfig {

    @Bean
    public DirectExchange workX() { return new DirectExchange("work.exchange"); }

    @Bean
    public Queue workQueue() {
        return QueueBuilder.durable("work.queue")
                .withArgument("x-dead-letter-exchange", "dlx.exchange")
                .withArgument("x-dead-letter-routing-key", "dlx.key")
                .withArgument("x-max-retries", 3)   // 自定义
                .build();
    }

    @Bean
    public Binding workB() {
        return BindingBuilder.bind(workQueue()).to(workX()).with("work.key");
    }

    /* ===== DLX ===== */
    @Bean public DirectExchange dlxX() { return new DirectExchange("dlx.exchange"); }
    @Bean public Queue dlxQueue() { return QueueBuilder.durable("dlx.queue").build(); }
    @Bean public Binding dlxB() {
        return BindingBuilder.bind(dlxQueue()).to(dlxX()).with("dlx.key");
    }
}
```

消费者手动 ack + 重试计数：

```java
@RabbitListener(queues = "work.queue")
public void handle(Message msg, Channel ch,
                   @Header(name = "x-retries", required = false) Integer retries) throws IOException {
    long deliveryTag = msg.getMessageProperties().getDeliveryTag();
    try {
        business(msg);          // 可能失败
        ch.basicAck(deliveryTag, false);
    } catch (Exception e) {
        int rt = retries == null ? 0 : retries;
        if (rt >= 3) {          // 超过上限 → 进 DLX
            ch.basicReject(deliveryTag, false);
        } else {                // 重新入队，计数+1
            msg.getMessageProperties().getHeaders().put("x-retries", rt + 1);
            ch.basicNack(deliveryTag, false, true);
        }
    }
}
```

#  六、方案总结

| 方案               | 一句话            | 适用场景               |
| ------------------ | ----------------- | ---------------------- |
| 1. Redis SETNX     | 内存高性能去重    | 并发高、可容忍短暂内存 |
| 2. 唯一索引        | 靠 DB 兜底        | 已有 DB、简单暴力      |
| 3. Kafka 幂等      | 开参数即可        | 仅用 Kafka 生产端      |
| 4. 事务消息+去重表 | 分布式事务级      | RocketMQ / 阿里系      |
| 5. 死信队列        | 失败兜底+重试上限 | 通用，配合任意 MQ 方案 |

